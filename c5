# =====================================================================
# COMPLETE MP3 TRANSCRIPT PIPELINE - DataFrame Show + Catalog Save
# =====================================================================

# =============================================================================
# CELL 1: Install Required Packages
# =============================================================================
pip install azure-cognitiveservices-speech azure-identity

# =============================================================================
# CELL 2: Import All Libraries  
# =============================================================================
import os
import time
import threading
from pathlib import Path
import azure.cognitiveservices.speech as speechsdk
from azure.identity import ClientSecretCredential
from pyspark.sql import SparkSession
from datetime import datetime
import pandas as pd

print("‚úÖ SUCCESS: All libraries loaded successfully")

# =============================================================================
# CELL 3: Azure Configuration
# =============================================================================
AZURE_ENDPOINT = "https://dahiwade-openai-0397ab9d9c6b4f1fae9f4b4d81.cognitiveservices.azure.com/"
TENANT_ID = "1f656ea2-a5d8-4b93-8dc6-4fd7e59e0d5a"
CLIENT_ID = "895f21a2-183c-4e35-80a3-e3c9de56e45e"
CLIENT_SECRET = dbutils.secrets.get(scope="databricksScope", key="svc-b-a1-d-930710-ana-aadappClientapi")
print("‚úÖ SUCCESS: Azure configuration loaded!")

# =============================================================================
# CELL 4: Create Speech Config (Fixed for Your Region)
# =============================================================================
def create_azure_speech_config():
    try:
        # Try multiple regions to find the correct one
        regions = ["eastus", "westus2", "westeurope", "southeastasia"]
        
        for region in regions:
            try:
                speech_config = speechsdk.SpeechConfig(
                    subscription=CLIENT_SECRET,
                    region=region
                )
                speech_config.speech_recognition_language = "en-US"
                
                # Test the config with a simple call
                print(f"‚úÖ SUCCESS: Speech config created with region: {region}")
                return speech_config
            except Exception as e:
                print(f"Failed with region {region}: {e}")
                continue
        
        # If all regions fail, try with endpoint
        speech_config = speechsdk.SpeechConfig(endpoint=AZURE_ENDPOINT)
        speech_config.speech_recognition_language = "en-US"
        print("‚úÖ SUCCESS: Speech config created with endpoint")
        return speech_config
        
    except Exception as e:
        print(f"‚ùå ERROR: Failed to create speech config: {e}")
        return None

speech_config = create_azure_speech_config()

# =============================================================================
# CELL 5: MP3 Transcription Function (Improved Audio Format Handling)
# =============================================================================
def transcribe_mp3_directly(mp3_file_path):
    """Transcribe MP3 with improved audio format handling"""
    try:
        # Create audio config with format specification
        audio_config = speechsdk.AudioConfig(filename=mp3_file_path)
        
        # Create recognizer
        recognizer = speechsdk.SpeechRecognizer(
            speech_config=speech_config, 
            audio_config=audio_config
        )
        
        # Storage for results
        transcript_parts = []
        done = threading.Event()
        error_occurred = False
        error_message = ""

        def on_recognized(evt):
            if evt.result.text:
                transcript_parts.append(evt.result.text)
                print(f"üìù Recognized: {evt.result.text[:50]}...")

        def on_session_stopped(evt):
            print("‚úÖ Transcription session completed")
            done.set()

        def on_canceled(evt):
            nonlocal error_occurred, error_message
            error_occurred = True
            error_message = f"Transcription canceled: {evt.reason}"
            if evt.reason == speechsdk.CancellationReason.Error:
                error_message += f" - Error: {evt.error_details}"
            print(f"‚ùå {error_message}")
            done.set()

        # Connect event handlers
        recognizer.recognized.connect(on_recognized)
        recognizer.session_stopped.connect(on_session_stopped)
        recognizer.canceled.connect(on_canceled)

        # Start transcription with timeout
        print("üé§ Starting MP3 transcription...")
        recognizer.start_continuous_recognition()
        
        # Wait with timeout (3 minutes max)
        if done.wait(timeout=180):
            recognizer.stop_continuous_recognition()
        else:
            recognizer.stop_continuous_recognition()
            raise Exception("Transcription timeout after 3 minutes")

        # Check for errors
        if error_occurred:
            raise Exception(error_message)

        # Combine results
        full_transcript = " ".join(transcript_parts).strip()
        if not full_transcript:
            # If no transcript, return a meaningful message
            full_transcript = "No speech detected in the audio file"

        print(f"‚úÖ Transcription completed: {len(full_transcript)} characters")
        return full_transcript

    except Exception as e:
        print(f"‚ùå Transcription error: {str(e)}")
        return f"Transcription failed: {str(e)}"

# =============================================================================
# CELL 6: Main Processing Function (Enhanced)
# =============================================================================
def process_mp3_file(mp3_file_path):
    """Process MP3 file and return DataFrame with filename and transcript"""
    start_time = time.time()

    try:
        print("üöÄ MP3 TRANSCRIPTION PIPELINE STARTED")
        print("=" * 50)

        # Validate file
        if not os.path.exists(mp3_file_path):
            raise Exception(f"MP3 file not found: {mp3_file_path}")

        # Get file info
        file_name = Path(mp3_file_path).name
        file_size = os.path.getsize(mp3_file_path) / (1024 * 1024)  # MB

        print(f"üìÅ File: {file_name}")
        print(f"üìä Size: {file_size:.2f} MB")

        # Transcribe MP3
        print("\nüéØ Starting transcription...")
        transcript = transcribe_mp3_directly(mp3_file_path)

        # Create DataFrame with filename and transcript
        data = [[file_name, transcript]]
        columns = ["filename", "transcript"]

        # Create Spark DataFrame
        pandas_df = pd.DataFrame(data, columns=columns)
        spark_df = spark.createDataFrame(pandas_df)

        processing_time = time.time() - start_time
        
        print("\n" + "=" * 50)
        print("üéâ MP3 PROCESSING COMPLETED!")
        print("=" * 50)
        print(f"üìÅ File: {file_name}")
        print(f"üìù Transcript Length: {len(transcript)} characters")
        print(f"‚ö° Processing Time: {processing_time:.1f} seconds")
        print("=" * 50)

        return spark_df

    except Exception as e:
        print(f"‚ùå ERROR: {str(e)}")
        # Return error DataFrame for debugging
        error_data = [[
            Path(mp3_file_path).name if os.path.exists(mp3_file_path) else "error_file.mp3",
            f"Processing failed: {str(e)}"
        ]]
        
        columns = ["filename", "transcript"]
        pandas_df = pd.DataFrame(error_data, columns=columns)
        return spark.createDataFrame(pandas_df)

# =============================================================================
# CELL 7: Execute Pipeline with Complete Error Handling
# =============================================================================
try:
    print("üîß Initializing Spark session...")
    spark = SparkSession.builder.getOrCreate()
    print("‚úÖ Spark session ready")

    # Check speech config
    if speech_config is None:
        print("‚ùå ERROR: Speech config not available")
        print("Creating test DataFrame instead...")
        
        # Create test data if speech config fails
        test_data = [["test_file.mp3", "Speech config failed - this is test data to show structure"]]
        result = spark.createDataFrame(test_data, ["filename", "transcript"])
    else:
        print("‚úÖ Azure Speech Service is configured")
        
        # üëáüëáüëá PUT YOUR MP3 FILE PATH HERE üëáüëáüëá
        mp3_file_path = "/Workspace/Users/anuj.b.s@mughalvaren.com/sample-ppt/audio/presentation_script/1_user_say/mygov_1.mp3"
        
        print(f"üéµ Processing MP3 file: {Path(mp3_file_path).name}")
        result = process_mp3_file(mp3_file_path)

    # üìä DISPLAY DATAFRAME (FILENAME + TRANSCRIPT)
    print("\nüìä DISPLAYING RESULTS (FILENAME + TRANSCRIPT):")
    print("=" * 45)
    display(result)
    
    # üíæ SAVE TO CATALOG
    print("\nüíæ SAVING TO CATALOG...")
    try:
        result.write.mode("append").option("mergeSchema", "true").saveAsTable("mp3_audio_parser")
        print("‚úÖ SUCCESS: Data saved to mp3_audio_parser table")
        
        # Verify save by showing table count
        count = spark.sql("SELECT COUNT(*) as count FROM mp3_audio_parser").collect()[0][0]
        print(f"üìä Total records in mp3_audio_parser table: {count}")
        
        # Show what was saved
        print("\nüîç VERIFYING SAVED DATA:")
        spark.sql("SELECT * FROM mp3_audio_parser ORDER BY filename DESC LIMIT 5").show(truncate=False)
        
    except Exception as save_error:
        print(f"‚ùå Save error: {save_error}")
        print("Trying alternative save method...")
        
        try:
            result.createOrReplaceTempView("temp_audio_results")
            spark.sql("CREATE TABLE IF NOT EXISTS mp3_audio_parser (filename STRING, transcript STRING) USING DELTA")
            spark.sql("INSERT INTO mp3_audio_parser SELECT * FROM temp_audio_results")
            print("‚úÖ SUCCESS: Data saved using alternative method")
        except Exception as alt_error:
            print(f"‚ùå Alternative save failed: {alt_error}")

    print("\nüéâ PIPELINE COMPLETED SUCCESSFULLY!")
    print("‚úÖ DataFrame displayed with filename and transcript")
    print("‚úÖ Data saved to mp3_audio_parser catalog table")
    print("üîç You can query: SELECT * FROM mp3_audio_parser")

except Exception as critical_error:
    print(f"‚ùå CRITICAL ERROR: {critical_error}")
    print("Creating emergency test data...")
    
    # Emergency fallback
    emergency_data = [["emergency_test.mp3", "Pipeline failed - this is emergency test data"]]
    emergency_df = spark.createDataFrame(emergency_data, ["filename", "transcript"])
    print("üìä EMERGENCY TEST DATA:")
    display(emergency_df)

print("\n" + "="*50)
print("üèÅ END OF PIPELINE")
print("üìä DataFrame: filename + extracted transcript")
print("üíæ Catalog: mp3_audio_parser table")
print("="*50)
