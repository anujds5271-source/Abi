# CELL 1: Install Required Packages
pip install azure-cognitiveservices-speech pandas

# CELL 2: Import All Libraries
import os
import time
import threading
import warnings
from pathlib import Path
from datetime import datetime
import pandas as pd
import azure.cognitiveservices.speech as speechsdk
from pyspark.sql import SparkSession
warnings.filterwarnings("ignore")
spark = SparkSession.builder.getOrCreate()
print("‚úÖ SUCCESS: All libraries loaded successfully")

# CELL 3: Azure Speech Subscription Config
SUBSCRIPTION_KEY = dbutils.secrets.get(scope="databricksScope", key="azureSpeechSubscriptionKey")
REGION = "centralindia"  # Replace with your Azure region
print("‚úÖ SUCCESS: Azure subscription config loaded")

# CELL 4: Create Azure Speech Config using subscription key
def create_azure_speech_config():
    speech_config = speechsdk.SpeechConfig(
        subscription=SUBSCRIPTION_KEY,
        region=REGION
    )
    speech_config.speech_recognition_language = "en-US"
    print("‚úÖ SUCCESS: Azure Speech Services configuration created.")
    return speech_config

# CELL 5: Transcribe audio from MP3 using Azure Speech Service
def transcribe_audio(file_path, speech_config):
    recognizer = speechsdk.SpeechRecognizer(
        speech_config=speech_config,
        audio_config=speechsdk.AudioConfig(filename=file_path)
    )
    done = threading.Event()
    transcript_parts = []

    def on_recognized(evt):
        if evt.result.text:
            transcript_parts.append(evt.result.text)

    def on_session_stopped(evt):
        done.set()

    def on_canceled(evt):
        print(f"‚ùå ERROR: Transcription canceled: {evt.reason}")
        done.set()

    recognizer.recognized.connect(on_recognized)
    recognizer.session_stopped.connect(on_session_stopped)
    recognizer.canceled.connect(on_canceled)

    recognizer.start_continuous_recognition()
    done.wait()
    recognizer.stop_continuous_recognition()

    full_transcript = " ".join(transcript_parts).strip()
    if not full_transcript:
        raise Exception("‚ùå No speech detected in audio.")

    return full_transcript

# CELL 6: MP3 Processing Pipeline
def process_mp3_file(mp3_file_path):
    start_time = time.time()
    try:
        print("üé§ MP3 TRANSCRIPTION PIPELINE STARTED")
        if not os.path.exists(mp3_file_path):
            raise Exception(f"‚ùå MP3 file not found: {mp3_file_path}")
        if not mp3_file_path.lower().endswith('.mp3'):
            raise Exception("‚ùå File must be in MP3 format")
        file_name = Path(mp3_file_path).name
        file_size = os.path.getsize(mp3_file_path) / (1024 * 1024)
        print(f"üìÑ File: {file_name} | üíæ Size: {file_size:.2f} MB")
        speech_config = create_azure_speech_config()
        transcript = transcribe_audio(mp3_file_path, speech_config)
        print("‚úÖ SUCCESS: Transcription completed.")
        data = [[file_name, transcript, datetime.now().strftime("%Y-%m-%d %H:%M:%S")]]
        columns = ["file_name", "transcript", "timestamp"]
        audio_df = pd.DataFrame(data, columns=columns)
        df = spark.createDataFrame(audio_df)
        print(f"‚úÖ DONE: Completed in {time.time() - start_time:.2f}s")
        return df
    except Exception as e:
        print(f"‚ùå ERROR: {e}")
        return None

# CELL 7: Run the transcription and save to Delta table
mp3_file_path = "/Workspace/Users/anuj.b.s@mughalvaren.com/sample-ppt/audio/presentation_script/1_user_say/mygov_1.mp3"
result = process_mp3_file(mp3_file_path)
if result:
    display(result)
    result.write.mode("append").saveAsTable("audio_transcripts")
    print("‚úÖ MP3 transcript pipeline completed and data saved to Delta table.")
else:
    print("‚ùå Transcription failed. Nothing to save.")
