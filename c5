print("DataFrame Info:")
print(f"Row count: {clean_df.count()}")
print(f"Columns: {clean_df.columns}")

# Show first few characters
clean_df.select("file_name", 
                clean_df.transcript.substr(1, 100).alias("transcript_preview")
               ).show(truncate=False)

```python
# 

def create_and_display_dataframe(result):
    file_name = os.path.basename(result["file_path"])
    transcript = result["transcript"]
    
    data = [(file_name, transcript)]
    columns = ["file_name", "transcript"]
    df = spark.createDataFrame(data, columns)
    
    print("DataFrame created successfully!")
    print(f"File: {file_name}")
    print(f"Transcript length: {len(transcript)} characters")
    
    print("\nDataFrame Schema:")
    df.printSchema()
    
    print("\nFull Transcript:")
    print("=" * 60)
    transcript_text = df.select("transcript").collect()[0][0]
    print(transcript_text)
    print("=" * 60)
    
    return df

if 'result' in locals() and result["status"] == "success":
    clean_df = create_and_display_dataframe(result)
```

## **Steps: