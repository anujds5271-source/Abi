# ============================================================================
# FIXED AUDIO FUNCTION - REPLACE YOUR EXISTING process_audio_file FUNCTION
# ============================================================================

def process_audio_file(audio_file_path):
    """
    Simple function to process audio file and create DataFrame
    FIXED: Using hardcoded Azure config values instead of metadata table
    """
    try:
        print(f"Processing audio file: {audio_file_path}")
        
        # FIXED: Use hardcoded Azure config values (same as Akshay's code)
        azure_endpoint = "https://bnlwe-ai04-d-930710-cognitive-01.cognitiveservices.azure.com/"
        tenant_id = "f66fae02-5d36-495b-bfe0-78a6ff9f8e6e"
        client_id = "898fc218-182c-4c53-8a31-e8f54c59ad59"
        client_secret = dbutils.secrets.get('databrickskv01', 'svc-b-ai-d-930710-ina-aadprincipal')
        
        # Create temp directory for audio processing
        workspace_audio_dir = "/tmp/audio_temp"
        os.makedirs(workspace_audio_dir, exist_ok=True)
        
        # Get audio duration to create segments
        from pydub import AudioSegment
        audio = AudioSegment.from_file(audio_file_path)
        duration_seconds = len(audio) / 1000
        
        # Create segments (5 minute chunks)
        segments = []
        segment_length = 300  # 5 minutes
        
        for start in range(0, int(duration_seconds), segment_length):
            end = min(start + segment_length, duration_seconds)
            segments.append((start, end))
        
        print(f"Created {len(segments)} segments for audio processing")
        
        # Call Akshay's get_transcripts function
        transcripts = get_transcripts(
            audio_file_path, 
            segments, 
            workspace_audio_dir,
            azure_endpoint,
            tenant_id,
            client_id,
            client_secret
        )
        
        # Convert transcripts to documents
        documents = transcripts_to_documents(transcripts, audio_file_path, audio_file_path)
        
        # Create DataFrame data
        page_content = []
        page_number = []
        
        for i, doc in enumerate(documents):
            page_content.append(doc.page_content)
            page_number.append(i + 1)
        
        file_path_list = [audio_file_path] * len(page_content)
        
        # Create pandas DataFrame
        data_dict = {
            'file_path': file_path_list, 
            'content': page_content, 
            'page_number': page_number
        }
        
        df = pd.DataFrame(data_dict)
        audio_spark_df = spark.createDataFrame(df)
        
        # Union with empty schema (same as other file types)
        empty_silver_schema = get_empty_silver_table_schema()
        if empty_silver_schema["status_code"] == 200:
            audio_spark_df = audio_spark_df.unionByName(empty_silver_schema["dataframe"], allowMissingColumns=True)
            
            # Clean up temp files
            import shutil
            shutil.rmtree(workspace_audio_dir, ignore_errors=True)
            
            return {
                "status_code": 200,
                "status_details": "ok",
                "dataframe": audio_spark_df
            }
        else:
            return {
                "status_code": 214,
                "status_details": empty_silver_schema["status_details"]
            }
            
    except Exception as e:
        print(f"Error in audio processing: {str(e)}")
        return {
            "status_code": 214,
            "status_details": str(e)
        }
