# ============================================================================
# STEP 1: ADD THESE INSTALLATIONS AT THE VERY TOP OF YOUR NOTEBOOK (CELL #1)
# REPLACE YOUR EXISTING CELL #1 WITH THIS
# ============================================================================

#1
import os
import pyspark.sql.functions as F
from pyspark.sql.types import *
import pandas as pd
from pyspark.sql import SparkSession
from pyspark.sql import Row
from datetime import datetime

# AUDIO INTEGRATION: Install required packages for audio processing
%pip install azure-cognitiveservices-speech
%pip install pydub
%pip install asyncio
%pip install python-dotenv

print("All audio dependencies installed successfully!")

# ============================================================================
# STEP 2: ADD THESE IMPORTS AFTER YOUR EXISTING %run COMMANDS (AFTER CELL #4)
# ============================================================================

# Add this after your existing %run commands
# AUDIO INTEGRATION: Import audio processing modules
import asyncio
import subprocess
import time
from concurrent.futures import ThreadPoolExecutor
from dotenv import load_dotenv
from langchain_core.documents import Document
from pydub import AudioSegment
import threading
import azure.cognitiveservices.speech as speechsdk
from azure.identity import ClientSecretCredential

print("Audio modules imported successfully!")

# ============================================================================
# STEP 3: ADD AKSHAY'S FUNCTIONS DIRECTLY (INSTEAD OF %run)
# ADD THIS AFTER YOUR IMPORTS, BEFORE CELL #5
# ============================================================================

# AUDIO INTEGRATION: Akshay's audio functions (copying directly instead of %run)

def get_azure_speect_to_text_config(rag_azure_cognitive_services_end_point, databricks_app_tenantid, databricks_app_clientid, spn_client_secret):
    """Get Azure Speech to Text configuration"""
    credential = ClientSecretCredential(
        tenant_id=databricks_app_tenantid,
        client_id=databricks_app_clientid,
        client_secret=spn_client_secret
    )
    token = credential.get_token("https://cognitiveservices.azure.com/.default").token
    speech_config = speechsdk.SpeechConfig(endpoint=rag_azure_cognitive_services_end_point)
    speech_config.authorization_token = token
    return speech_config

def transcripts_to_documents(transcripts, audio_path, volume_path_with_file_name):
    """Convert transcripts to document format"""
    print(f"Converting transcripts to documents for: {audio_path}")
    audio_file_name = os.path.splitext(os.path.basename(audio_path))[0]
    documents = []
    for (start, end), text in transcripts:
        doc = Document(
            page_content=text,
            metadata={
                "start_second": start,
                "end_second": end,
                "type": "transcript",
                "file_path": volume_path_with_file_name,
            },
        )
        documents.append(doc)
    return documents

def transcribe_segment_sync(audio_path, start_sec, end_sec, workspace_audio_dir_path, speech_config):
    """Transcribe a single audio segment"""
    print(f"Transcribing segment: {start_sec}-{end_sec} seconds")
    audio = AudioSegment.from_file(audio_path)
    start_ms = int(start_sec * 1000)
    end_ms = int(end_sec * 1000)
    segment = audio[start_ms:end_ms]
    segment_path = f"{workspace_audio_dir_path}/temp_{start_ms}_{end_ms}.wav"
    segment.export(segment_path, format="wav")
    
    try:
        audio_input_config = speechsdk.AudioConfig(filename=segment_path)
        speech_recognizer = speechsdk.SpeechRecognizer(
            speech_config=speech_config,
            audio_config=audio_input_config
        )
        
        full_transcript = []
        def handle_final_result(evt):
            if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:
                print(f"Recognized: {evt.result.text[:50]}...")
                full_transcript.append(evt.result.text)
            elif evt.result.reason == speechsdk.ResultReason.NoMatch:
                print("No speech could be recognized")
        
        done = threading.Event()
        def stop_cb(evt):
            print("Recognition finished.")
            done.set()
        
        speech_recognizer.recognized.connect(handle_final_result)
        speech_recognizer.session_stopped.connect(stop_cb)
        speech_recognizer.canceled.connect(stop_cb)
        
        speech_recognizer.start_continuous_recognition()
        done.wait()
        speech_recognizer.stop_continuous_recognition()
        
        # Clean up segment file
        try:
            os.remove(segment_path)
        except:
            pass
            
        return " ".join(full_transcript)
    except Exception as e:
        print(f"Error transcribing segment: {str(e)}")
        return ""

semaphore = asyncio.Semaphore(5)

async def transcribe_segment(audio_path, start_sec, end_sec, executor, workspace_audio_dir_path, speech_config):
    """Async transcribe segment"""
    async with semaphore:
        loop = asyncio.get_running_loop()
        result = await loop.run_in_executor(
            executor,
            transcribe_segment_sync,
            audio_path,
            start_sec,
            end_sec,
            workspace_audio_dir_path,
            speech_config
        )
        return result

async def transcribe_multiple_segments(audio_path, segments, workspace_audio_dir_path, speech_config):
    """Transcribe multiple segments asynchronously"""
    print(f"Transcribing {len(segments)} segments")
    executor = ThreadPoolExecutor(max_workers=5)
    tasks = [
        transcribe_segment(audio_path, start, end, executor, workspace_audio_dir_path, speech_config) 
        for start, end in segments
    ]
    transcripts = await asyncio.gather(*tasks)
    return list(zip(segments, transcripts))

def get_transcripts(audio_path, segments, workspace_audio_dir_path, rag_azure_cognitive_services_end_point, databricks_app_tenantid, databricks_app_clientid, spn_client_secret):
    """Main function to get transcripts from audio"""
    print(f"Starting transcription for {len(segments)} segments")
    start_time = time.perf_counter()
    
    speech_config = get_azure_speect_to_text_config(
        rag_azure_cognitive_services_end_point, 
        databricks_app_tenantid, 
        databricks_app_clientid, 
        spn_client_secret
    )
    
    transcripts = asyncio.run(transcribe_multiple_segments(audio_path, segments, workspace_audio_dir_path, speech_config))
    
    end_time = time.perf_counter() - start_time
    print(f"Transcription completed in {end_time:.2f} seconds")
    return transcripts

print("Audio processing functions loaded successfully!")

# ============================================================================
# NOW YOUR EXISTING CELLS CONTINUE FROM CELL #5 ONWARDS
# ============================================================================